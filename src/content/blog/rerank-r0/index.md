---
title: 'Rerank R0ï¼ˆå¾…ç»­ï¼‰'
description: 'åŸºäºæ¨ç†æ¨¡å‹çš„LLM Based Rerankæ¨¡å‹'
publishDate: 2025-10-15
updatedDate: 2025-10-15
tags:
  - Rerank
  - æ¨¡å‹æ¢ç´¢
comment: true
heroImage:
  src: './rerank-main.jpg'
---
# Rerank R0

## åˆå§‹æ¨¡å‹

åˆå§‹æ¨¡å‹æ˜¯ `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`ã€‚

## é¡¹ç›®æ¦‚è§ˆ

è¿™æ˜¯ä¸€ä¸ªæ–‡æ¡£é‡æ’åºé¡¹ç›®ï¼Œç»“åˆäº† ProRank ä¸ Rank-R1 ä¸¤ç¯‡è®ºæ–‡çš„æ€è·¯ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆPPOï¼‰è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿå…ˆæ€è€ƒå†æ’åºçš„æ¨¡å‹ã€‚

## é¡¹ç›®ç›®æ ‡

- è®­ç»ƒä¸€ä¸ªä¼šâ€œå…ˆæ€è€ƒå†æ’åºâ€çš„æ–‡æ¡£é‡æ’åºæ¨¡å‹
- ä¼˜åŒ–æ¨ç†å‹åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1 åŠå…¶è’¸é¦ç‰ˆæœ¬ï¼‰çš„æ’åºè¡¨ç°
- å½“å‰ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹ï¼š`deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`

## é¡¹ç›®åŸºçŸ³

ç°æœ‰ Rerank æ¨¡å‹çš„ä¸»æµåšæ³•æ˜¯åœ¨ LLM è¾“å‡ºå±‚åŠ ä¸€ä¸ªäºŒåˆ†ç±»å¤´ï¼ˆsoftmax over "yes"/"no"ï¼‰ã€‚æˆ‘ä»¬å‡è®¾æ¨ç†æ¨¡å‹çš„æ€è€ƒèƒ½åŠ›ä¼˜äºåŸºç¡€æ¨¡å‹ï¼Œåœ¨è¯­ä¹‰ç†è§£å±‚é¢æœ‰æ½œåœ¨ä¼˜åŠ¿ï¼Œå› æ­¤é€šè¿‡å¼•å¯¼æ¨¡å‹â€œå…ˆæ€è€ƒåå›ç­”â€æå‡æ’åºè´¨é‡ã€‚

## é¡¹ç›®ç»“æ„

```bash
rerank-r0/
â”œâ”€â”€ prorank/                # æ ¸å¿ƒä»£ç æ¨¡å—
â”‚   â”œâ”€â”€ config.py           # é…ç½®åŠ è½½
â”‚   â”œâ”€â”€ data.py             # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ models.py           # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ reward.py           # å¥–åŠ±å‡½æ•°
â”‚   â”œâ”€â”€ trainer.py          # PPO è®­ç»ƒä¸»ç¨‹åº
â”‚   â”œâ”€â”€ sft_stage_a.py      # SFT ç›‘ç£å¾®è°ƒè®­ç»ƒ
â”‚   â””â”€â”€ utils.py            # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ convert_data.py     # æ•°æ®æ ¼å¼è½¬æ¢è„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ stage_a.yaml        # é˜¶æ®µ A è®­ç»ƒé…ç½®
â”œâ”€â”€ deepspeed_zero2.json    # DeepSpeed é…ç½®
â”œâ”€â”€ pyproject.toml          # é¡¹ç›®ä¾èµ–é…ç½®
â””â”€â”€ project.md              # é¡¹ç›®æ–¹æ¡ˆæ–‡æ¡£
```

## ä¸»è¦ç»„ä»¶

- é˜¶æ®µ A è®­ç»ƒï¼šé€šè¿‡ PPO å¼ºåŒ–å­¦ä¹ è®©æ¨¡å‹æŒæ¡è§„èŒƒè¾“å‡ºä¸äºŒåˆ†ç±»åˆ¤æ–­
- æ•°æ®è½¬æ¢ï¼šå°†åŸå§‹æ—¥å¿—æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ‰€éœ€æ ¼å¼
- è§„åˆ™å¥–åŠ±ï¼šç»“åˆæ ¼å¼ã€å‡†ç¡®æ€§ä¸é•¿åº¦æ§åˆ¶å½¢æˆå¥–åŠ±ä¿¡å·

## å¿«é€Ÿå¼€å§‹

### 1. æ•°æ®å‡†å¤‡

ä»æ—¥å¿—ä¸­æŠ½å–æ•°æ®ï¼Œå¹¶ä½¿ç”¨åƒå¯»ä¸­çš„ DS R1 æ¨¡å‹è¿è¡ŒæŒ‡å®š Promptï¼š

```bash
Evaluate if the Document comprehensively addresses the Query. All key concepts in the Query must be present and properly connected in the Document. The Document should provide information about the relationship between all query terms, not just mention them in isolation. Answer "yes" only if the Document satisfies the complete information need. Output exactly "yes" or "no".
```

å¦‚æœéœ€è¦è½¬æ¢åŸå§‹æ•°æ®ï¼Œæ‰§è¡Œï¼š

```python
python scripts/convert_data.py <input_jsonl> <output_jsonl> --max-think-chars 1200000
```

### 2. æ•°æ®æ ¼å¼è¦æ±‚

**è¾“å…¥ JSONL**

```json
{
  "query": "ï¼ˆç”¨æˆ·é—®é¢˜ / æ£€ç´¢è¯·æ±‚ï¼‰",
  "response": "ï¼ˆæ¨¡å‹åˆ¤å®šä¸ºæœ€ä¼˜çš„æ–‡æ¡£æˆ–æ‘˜è¦ç‰‡æ®µï¼‰",
  "response_thinking": "ï¼ˆè§£é‡Šä¸ºä»€ä¹ˆ response èƒ½å¾ˆå¥½åœ°è¦†ç›– query çš„åˆ†ææ¨ç†ï¼‰",
  "rejected_response": [
    {
      "document": "ï¼ˆè¢«å¦å†³çš„å€™é€‰æ–‡æ¡£ 1ï¼‰",
      "thinking": "ï¼ˆå¦å†³ç†ç”± / ä¸ºä»€ä¹ˆè¯¥æ–‡æ¡£ä¸å¦‚ responseï¼‰"
    },
    {
      "document": "ï¼ˆè¢«å¦å†³çš„å€™é€‰æ–‡æ¡£ 2ï¼‰",
      "thinking": "ï¼ˆå¦å†³ç†ç”± / ä¸ºä»€ä¹ˆè¯¥æ–‡æ¡£ä¸å¦‚ responseï¼‰"
    }
  ]
}
```

**è¾“å‡º JSONL**

```json
{
  "query": "ï¼ˆç”¨æˆ·é—®é¢˜ / æ£€ç´¢è¯·æ±‚ï¼‰",
  "document": "ï¼ˆæ¨¡å‹åˆ¤å®šä¸ºæœ€ä¼˜çš„æ–‡æ¡£æˆ–æ‘˜è¦ç‰‡æ®µï¼‰",
  "think": "ï¼ˆè§£é‡Šä¸ºä»€ä¹ˆ response èƒ½å¾ˆå¥½åœ°è¦†ç›– query çš„åˆ†ææ¨ç†ï¼‰",
  "answer": "yes",
  "label": 1
}
```

### 3. å¯åŠ¨è®­ç»ƒ

å¯åŠ¨é˜¶æ®µ A çš„ PPO è®­ç»ƒï¼š

```python
python prorank/trainer.py --config configs/stage_a.yaml
```

è®­ç»ƒç›®æ ‡ï¼š

- ä¸¥æ ¼éµå®ˆ `<think>`/`<answer>` è¾“å‡ºæ ¼å¼
- æå‡æ–‡æ¡£ç›¸å…³æ€§åˆ¤æ–­å‡†ç¡®ç‡
- æ§åˆ¶æ€è€ƒé•¿åº¦ï¼Œé¿å…è¿‡åº¦è¾“å‡º

## é…ç½®æ–‡ä»¶è¯¦è§£

`configs/stage_a.yaml` ä¸­çš„å…³é”®é…ç½®å¦‚ä¸‹ï¼š

```yaml
# Training
epochs: 1
batch_size: 2
learning_rate: 6e-6
kl_coef: 0.02
seed: 42

# Generation
max_new_tokens: 256
temperature: 0.7
top_p: 1.0
max_think_tokens: 200
gradient_checkpointing: true
missing_eos_penalty: 0.5

# Prompts
system_prompt: |
  [system]
  You are a document relevance evaluator. Your task is to determine if a Document comprehensively addresses a given Query.

  Evaluation Criteria:
  - ALL key concepts from the Query must be present in the Document
  - The Document must explain relationships and connections between query terms
  - Isolated mentions without context are insufficient
  - The Document should satisfy the complete information need expressed in the Query

  Process:
  1. First, analyze in <think> tags (max 128 tokens): identify key concepts in the Query, check their presence and interconnection in the Document
  2. Then output your final judgment in <answer> tags: exactly "yes" for comprehensive coverage or "no" for insufficient coverage
  3. Do not output any other characters or explanations outside these tags

  Only answer "yes" if the Document fully satisfies the Query's information requirements.

# Reward config
reward:
  format_weight: 0.4
  acc_weight: 0.5
  length_penalty: 0.05
  max_think_tokens: 200
  extra_text_penalty: 0.2
  invalid_tag_penalty: 0.5
  missing_answer_penalty: 0.3
  think_bonus: 0.3
  min_think_tokens: 64

# PPO extras - Fixed parameter names
ppo:
  num_ppo_epochs: 2
  cliprange: 0.2
  cliprange_value: 0.2
  vf_coef: 0.2
  gamma: 0.99
  lam: 0.95
  whiten_rewards: false
```

## è®­ç»ƒæµç¨‹

é˜¶æ®µ Aï¼šPrompt ä¸äºŒåˆ†ç±» Warmupã€‚

1. æ¨¡å‹åŠ è½½ï¼šåŠ è½½åŸºç¡€æ¨¡å‹ä¸ tokenizer
2. æ•°æ®å¤„ç†ï¼šæ„å»º PPO è®­ç»ƒæ•°æ®é›†
3. å¥–åŠ±è®¾è®¡ï¼šç»„åˆæ ¼å¼ã€å‡†ç¡®æ€§ã€é•¿åº¦æ§åˆ¶ç­‰è§„åˆ™å¥–åŠ±
4. PPO è®­ç»ƒï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥
5. æ¨¡å‹ä¿å­˜ï¼šè¾“å‡ºè®­ç»ƒå¥½çš„æ¨¡å‹ä¸ tokenizer

## å¥–åŠ±å‡½æ•°æœºåˆ¶

é¡¹ç›®ä½¿ç”¨è§„åˆ™å¥–åŠ±æ¨¡å‹è¯„ä¼°è¾“å‡ºï¼šå®ç°ä¸€ä¸ªä¼ªç¥ç»ç½‘ç»œï¼ˆç»§æ‰¿ `nn.Module`ï¼‰ï¼Œé€šè¿‡ç¼“å­˜ `input_ids` ä¸è§„åˆ™è®¡ç®— reward æ¥é€‚é… TRL æ¥å£ã€‚ç›¸æ¯”è®­ç»ƒæ˜‚è´µçš„ç¥ç»ç½‘ç»œå¥–åŠ±æ¨¡å‹ï¼Œæ­¤æ–¹æ¡ˆæ›´è½»é‡ï¼›å¯¹äºçº¯è§„åˆ™å¥–åŠ±çš„åœºæ™¯ï¼Œåç»­å¯è€ƒè™‘åˆ‡æ¢ GRPO ä»¥è·å¾—æ›´é«˜æ•ˆç‡ã€‚

```bash
TRL Trainer
    â”‚
    â”œâ”€> è°ƒç”¨ model.backbone(input_ids)
    â”‚       â”‚
    â”‚       â””â”€> _DummyBackbone.forward()
    â”‚               â”œâ”€ ç¼“å­˜ input_ids åˆ° self._cached_input_ids
    â”‚               â””â”€ è¿”å›å‡çš„ hidden_statesï¼ˆå…¨é›¶å¼ é‡ï¼‰
    â”‚
    â””â”€> è°ƒç”¨ model.score(hidden_states)
            â”‚
            â””â”€> RuleRewardModel.score()
                    â”œâ”€ å¿½ç•¥ hidden_states
                    â”œâ”€ ä»ç¼“å­˜ä¸­è¯»å– input_ids
                    â”œâ”€ å¯¹æ¯ä¸ªæ ·æœ¬ï¼š
                    â”‚     â”œâ”€ åŒ¹é… token å‰ç¼€æ‰¾åˆ°æ ‡ç­¾
                    â”‚     â”œâ”€ è§£ç ç”Ÿæˆéƒ¨åˆ†ä¸ºæ–‡æœ¬
                    â”‚     â””â”€ ç”¨è§„åˆ™è®¡ç®—å¥–åŠ±
                    â””â”€ è¿”å› [B, L, 1] å¥–åŠ±å¼ é‡
```

### å¥–åŠ±é¡¹æ‹†è§£

- `format_weight (0.4)`: è¾“å‡º `<answer>yes/no</answer>` æ—¶å¥–åŠ± `+0.4`
- `acc_weight (0.5)`: åˆ†ç±»æ­£ç¡®å¥–åŠ± `+0.5`
- `think_bonus (0.3)`: æ€è€ƒ token æ•°åœ¨ `[64, 200]` å†…å¥–åŠ± `+0.3`
- `length_penalty (0.05)`: è¶…å‡º `max_think_tokens` æ—¶æŒ‰æ¯”ä¾‹æ‰£åˆ†
- `extra_text_penalty (0.2)`: `</answer>` ä¹‹åå­˜åœ¨é¢å¤–æ–‡æœ¬æ—¶æ‰£åˆ†
- `invalid_tag_penalty (0.5)`: ç¼ºå¤± `<think>` æˆ– `<answer>` æ ‡ç­¾æ—¶æ‰£åˆ†
- `missing_answer_penalty (0.3)`: ç¼ºå°‘ `<answer>` æ—¶ç›´æ¥æ–½åŠ é¢å¤–è´Ÿåˆ†ï¼Œæ€»æ‰£åˆ†æœ€é«˜è‡³ `-0.8`
- `min_think_tokens` / `max_think_tokens`: çº¦æŸæ€è€ƒé•¿åº¦ä»¥è§¦å‘å¥–åŠ±æˆ–æƒ©ç½š

ç¤ºä¾‹ï¼š

- æ­£ç¡®ï¼š`<think>...</think><answer>yes</answer>`
- é”™è¯¯ï¼š`<think>...</think><answer>yes</answer> This is extra text!`

## è®­ç»ƒè®°å½•

![image](./train-process-1.png)

![image](./train-process-2.png)

![image](./train-process-3.png)

## æ¨¡å‹æ¨ç†æ ¼å¼

è®­ç»ƒåçš„æ¨¡å‹è¾“å‡ºç¤ºä¾‹ï¼š

```
<think>
è¿™é‡Œæ˜¯æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œåˆ†æ query å’Œ document çš„ç›¸å…³æ€§...
</think>
<answer>yes</answer>
```

![image](./inference-1.png)

![image](./inference-2.png)

![image](./inference-3.png)

![image](./inference-4.png)

## åç»­é˜¶æ®µè§„åˆ’

- é˜¶æ®µ Aï¼ˆå½“å‰ï¼‰ï¼šPrompt ä¸äºŒåˆ†ç±» Warmup
- é˜¶æ®µ Bï¼šListwise æ¨ç†æ’åºå¼ºåŒ–
- é˜¶æ®µ Cï¼šç»†ç²’åº¦ç›‘ç£å¾—åˆ†å­¦ä¹ 

## è¿ç§»åˆ° MobileLLM-R1-950M

ğŸ“‹ **æ¦‚è¿°**ï¼šæ–°æ¨¡å‹å‚æ•°æ›´å°ã€æ¨ç†æ›´å¿«ï¼ŒåŒæ—¶ä¿æŒè‰¯å¥½è¡¨ç°ã€‚

| ç‰¹æ€§ | DeepSeek-R1 1.5B | MobileLLM-R1 950M |
| --- | --- | --- |
| å‚æ•°é‡ | 1.5B | 950M âš¡ |
| æ¨ç†èƒ½åŠ› | è’¸é¦æ¨¡å‹ | åŸç”Ÿæ¨ç†è®­ç»ƒ ğŸ¯ |
| è®­ç»ƒæ•°æ® | é€šç”¨ | å¤§é‡æ¨ç†æ•°æ®é›† ğŸ“š |
| æ˜¾å­˜å ç”¨ | ~6GB | ~4GB âš¡ |
| è®­ç»ƒé€Ÿåº¦ | åŸºå‡† | ~1.5x æ›´å¿« âš¡ |
| è®¸å¯è¯ | Apache 2.0 | FAIR NCï¼ˆä»…éå•†ä¸šï¼‰âš ï¸ |

### æ³¨æ„äº‹é¡¹

- è®¸å¯è¯é™åˆ¶ï¼šä»…é™éå•†ä¸šç ”ç©¶ä½¿ç”¨
- è‹¥éœ€å•†ä¸šéƒ¨ç½²ï¼Œè¯·ç»§ç»­ä½¿ç”¨ DeepSeek-R1
